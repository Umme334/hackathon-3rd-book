"use strict";(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[7711],{4513:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>u,frontMatter:()=>r,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"humanoid-robotics/perception","title":"Humanoid Perception Systems","description":"This is a placeholder page for the Humanoid Perception Systems section. Perception is crucial for humanoid robots to understand their environment, interact with objects, and engage with humans effectively.","source":"@site/docs/humanoid-robotics/perception.md","sourceDirName":"humanoid-robotics","slug":"/humanoid-robotics/perception","permalink":"/textbook-generation/textbooks/humanoid-robotics/perception","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/humanoid-robotics/perception.md","tags":[],"version":"current","lastUpdatedBy":null,"lastUpdatedAt":null,"sidebarPosition":3,"frontMatter":{"sidebar_position":3,"title":"Humanoid Perception Systems"},"sidebar":"tutorialSidebar","previous":{"title":"Humanoid Control Systems","permalink":"/textbook-generation/textbooks/humanoid-robotics/control-systems"},"next":{"title":"ROS 2 for Physical AI","permalink":"/textbook-generation/textbooks/software/ros2"}}');var o=i(4848),s=i(8453);const r={sidebar_position:3,title:"Humanoid Perception Systems"},a="Humanoid Perception Systems",l={},c=[{value:"Sensory Modalities",id:"sensory-modalities",level:2},{value:"Computer Vision",id:"computer-vision",level:2},{value:"Auditory Processing",id:"auditory-processing",level:2},{value:"Multisensory Integration",id:"multisensory-integration",level:2},{value:"Human-Robot Interaction",id:"human-robot-interaction",level:2}];function d(e){const n={h1:"h1",h2:"h2",header:"header",li:"li",p:"p",ul:"ul",...(0,s.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.header,{children:(0,o.jsx)(n.h1,{id:"humanoid-perception-systems",children:"Humanoid Perception Systems"})}),"\n",(0,o.jsx)(n.p,{children:"This is a placeholder page for the Humanoid Perception Systems section. Perception is crucial for humanoid robots to understand their environment, interact with objects, and engage with humans effectively."}),"\n",(0,o.jsx)(n.h2,{id:"sensory-modalities",children:"Sensory Modalities"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Vision systems (stereo, RGB-D cameras)"}),"\n",(0,o.jsx)(n.li,{children:"Auditory processing"}),"\n",(0,o.jsx)(n.li,{children:"Tactile sensing"}),"\n",(0,o.jsx)(n.li,{children:"Proprioception"}),"\n",(0,o.jsx)(n.li,{children:"Spatial awareness"}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"computer-vision",children:"Computer Vision"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Object recognition and tracking"}),"\n",(0,o.jsx)(n.li,{children:"Human pose estimation"}),"\n",(0,o.jsx)(n.li,{children:"Scene understanding"}),"\n",(0,o.jsx)(n.li,{children:"Visual SLAM"}),"\n",(0,o.jsx)(n.li,{children:"Face recognition and expression analysis"}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"auditory-processing",children:"Auditory Processing"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Speech recognition"}),"\n",(0,o.jsx)(n.li,{children:"Sound localization"}),"\n",(0,o.jsx)(n.li,{children:"Noise filtering"}),"\n",(0,o.jsx)(n.li,{children:"Natural language understanding"}),"\n",(0,o.jsx)(n.li,{children:"Audio-visual integration"}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"multisensory-integration",children:"Multisensory Integration"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Sensor fusion techniques"}),"\n",(0,o.jsx)(n.li,{children:"Cross-modal learning"}),"\n",(0,o.jsx)(n.li,{children:"Attention mechanisms"}),"\n",(0,o.jsx)(n.li,{children:"Uncertainty management"}),"\n",(0,o.jsx)(n.li,{children:"Real-time processing constraints"}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"human-robot-interaction",children:"Human-Robot Interaction"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Social signal processing"}),"\n",(0,o.jsx)(n.li,{children:"Intention recognition"}),"\n",(0,o.jsx)(n.li,{children:"Emotional state detection"}),"\n",(0,o.jsx)(n.li,{children:"Gaze tracking"}),"\n",(0,o.jsx)(n.li,{children:"Gesture recognition"}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:"This section will be expanded with comprehensive information about humanoid robot perception systems and technologies."})]})}function u(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(d,{...e})}):d(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>r,x:()=>a});var t=i(6540);const o={},s=t.createContext(o);function r(e){const n=t.useContext(s);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:r(e.components),t.createElement(s.Provider,{value:n},e.children)}}}]);